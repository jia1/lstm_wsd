Target to beat: 0.662

1.
With forward LSTM full length. No stemming. No stop words. No unsupervised training.
min_freq=5 => Vocabulary size: 14329
Cost (train/val): 2.053906/2.041744, Accuracy (train/val): 0.482063/0.471905


2.
As (1.), but with stemming.
min_freq=5 => Vocabulary size: 11079
Cost (train/val): 2.062860/2.011632, Accuracy (train/val): 0.479048/0.485238


3.
As (2.), but with variable input sequence length.
n_step = 20
EPOCH: 348
Cost (train/val): 1.589458/1.553583, Accuracy (train/val): 0.479677/0.484500

4.
As (3.), but with forward AND backward LSTM (bidirectional).
EPOCH: 138
Cost (train/val): 1.732096/1.760567, Accuracy (train/val): 0.482321/0.476250

5.
As 4, but fixed broadcasting bug.
EPOCH: 41
Cost (train/val): 0.791101/1.865055, Accuracy (train/val): 0.720645/0.480000

6.
As 5, but with glove.
EPOCH: 41
Cost (train/val): 0.727260/2.038966, Accuracy (train/val): 0.742097/0.456000

7.
Dropout on embeddings
EPOCH: 53
TRAIN ::: cost: 0.687805, accuracy: 0.754677
VAL ::: cost: 2.504641, accuracy: 0.392258





todo
stop words
unsupervised
